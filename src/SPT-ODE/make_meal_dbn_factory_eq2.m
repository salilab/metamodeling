% Make a DBN for the meal model with the following variables
%
% Time-dependent variables
%  -> G.Meal(t)  ->  G.Meal(t+1) ->
%  -> I.Meal(t)  ->  I.Meal(t+1) ->
%
% Reference variables
% G.ref(t), G.ref(t+1)
% I.ref(t), I.ref(t+1)
%
% Observed variables
% G.obs(t), G.obs(t+1)
% I.obs(t), I.obs(t+1)
%
% Time-invariant variables
% Gb.Meal
%
% Parameters
% ALPHA BETA
%
% To generate a conditional gaussian model
function [dbn_factory]= make_meal_dbn_factory_eq2(G_Meal, I_Meal, alpha_Meal,beta_Meal, K_Meal, dt_Meal, DG_Meal, Gb_Meal, Sb_Meal)
    node_names=  {'G.Meal','G.ref','G.obs','Gb.Meal','G_minus_Gb.Meal','DG.Meal','DG.ref','DG.obs','I.Meal','Sb.Meal','S.Meal','S.ref','S.obs'}; % BARAK comment: removed alpha, beta (turned to weights) + added intermediate (G-h)
    n= length(node_names);
    % Intra - in one time slice
    edges_intra= {'Gb.Meal','G_minus_Gb.Meal'; 'G.Meal','G_minus_Gb.Meal'; 'G.Meal', 'G.ref';...
        'G.ref','G.obs'; 'DG.Meal', 'DG.ref';'DG.ref','DG.obs';'DG.Meal','S.Meal';'I.Meal','S.Meal';'Sb.Meal','S.Meal';'S.Meal','S.ref';'S.ref','S.obs'};
    % Inter - between time slices
    edges_inter= { 'G.Meal', 'G.Meal'; 'Gb.Meal', 'Gb.Meal';'G_minus_Gb.Meal','G_minus_Gb.Meal'; ...
        'G_minus_Gb.Meal','I.Meal';'I.Meal', 'I.Meal'; 'DG.Meal', 'DG.Meal'; 'Sb.Meal','Sb.Meal' }; % BARAK comment: switched G->I and h->I to (G-h)->I
    eclass1_map= containers.Map();
    eclass2_map= containers.Map();
    for i=1:numel(node_names)
        node_name= node_names{i};
        cpd_name= [ node_name '.intra' ];
        eclass1_map(node_name) = cpd_name;
        eclass2_map(node_name) = cpd_name; % default - to be changed for some special cases
    end
    eclass2_map('Gb.Meal')= 'Gb.Meal.inter';
    eclass2_map('G.Meal')= 'G.Meal.inter';
    eclass2_map('DG.Meal')= 'DG.Meal.inter';   
    eclass2_map('G_minus_Gb.Meal')= 'G.minus.Gb.Meal.inter';
    eclass2_map('I.Meal')= 'I.Meal.inter';   
    eclass2_map('Sb.Meal')= 'Sb.Meal.inter';   
    eclass2_map('S.Meal')= 'S.Meal.inter';   
    
    % elcass1 (time-slice 0 or all parents are in the same time slice)
    
    CPDFactories= {};
    CPDFactories{end+1}=  ...
        CPDFactory('Gaussian_CPD', 'Gb.Meal', 0, ...
        {'mean', Gb_Meal,   'cov', 0.001} );
    CPDFactories{end+1}=  ...
        CPDFactory('Gaussian_CPD', 'G.Meal', 0, ...
        {'mean', G_Meal, 'cov', 0.001} ); 
    weights_G_minus_h0_map_T0= containers.Map(); % parents in slice t
    weights_G_minus_h0_map_T1= containers.Map(); % parents in slice t+1
    weights_G_minus_h0_map_T0('G.Meal')= 1.0;
    weights_G_minus_h0_map_T0('Gb.Meal')= -1.0;
    % When using clamp, the root node is clamped to the N(0,I) distribution, so that we will not update these parameters during learning. 
    CPDFactories{end+1}=  ...
        CPDFactory('Gaussian_CPD', 'G_minus_Gb.Meal', 0, ...
        {'mean', 0.0, 'cov', 0.001}, ...
        weights_G_minus_h0_map_T0, weights_G_minus_h0_map_T1); % G_minus_h ~ Norm(E(G)-E(h))
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'G.ref', 0,   ...
        {'mean', 0.0,'cov', 0.001, 'weights', 1.0} ); % E= [1.0*G(t)] 
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'G.obs', 0, ...
        {'mean', 0.0,'cov', 0.001, 'weights', 1.0}); % E= [1.0*Gref(t)]
    CPDFactories{end+1}=  ...
        CPDFactory('Gaussian_CPD', 'DG.Meal', 0, ...
        {'mean', DG_Meal,   'cov', 10e-10, 'clamp_cov', 10e-10});
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'DG.ref', 0, ...
        { 'mean', 0.0,'cov', 10e-10, 'clamp_cov', 10e-10,  'weights', 1.0} ); % E= [1.0*I(t)] 
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'DG.obs', 0, ...   
        {'mean', 0.0,'cov', 10e-10, 'clamp_cov', 10e-10, 'weights', 1.0} ); % E= [1.0*Iref(t)]
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'I.Meal', 0, ...
        {'mean', I_Meal, 'cov', 0.001} ); 
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'Sb.Meal', 0, ...
        {'mean', Sb_Meal, 'cov', 0.00001} ); 
    weights_S0_map_T0= containers.Map(); % parents in slice t
    weights_S0_map_T1= containers.Map(); % parents in slice t+1
    INITIAL_K = K_Meal;%%%%%%%%condition for K
    weights_S0_map_T0('DG.Meal')= 0.0;
    weights_S0_map_T0('Sb.Meal')= 1.0;
    weights_S0_map_T0('I.Meal')= 0.0;
    % When using clamp, the root node is clamped to the N(0,I) distribution, so that we will not update these parameters during learning. 
    CPDFactories{end+1}=  ...
        CPDFactory('Gaussian_CPD', 'S.Meal', 0, ...
        {'mean', 0.0, 'cov', 0.001}, ...
        weights_S0_map_T0, weights_S0_map_T1);
    %,'clamp_mean', 1, 'clamp_cov', 1, 'clamp_weights', 1); % G_minus_h ~ Norm(E(G)-E(h))
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'S.ref', 0, ...
        { 'mean', 0.0,'cov', 0.001,   'weights', 1.0} ); % E= [1.0*I(t)] 
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'S.obs', 0, ...   
        {'mean', 0.0,'cov', 0.001,   'weights', 1.0} ); % E= [1.0*Iref(t)]
    % eclass2 (time-slice t+1 with parents in the previous time slice)
    
    % CPD for h(t+1), forcing h to be nearly constant
    CPDFactories{end+1} = ...
       CPDFactory('Gaussian_CPD', 'Gb.Meal', 1, ...
        {'mean',0.0,'cov', 0.001, 'weights', 1.0} ); % E[Gb(t+1) ] = 1.0*Gb(t) +- 0.2    
    % CPD for G(t+1)
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'G.Meal', 1, ...
        {'mean',0.0,'cov', 0.001, 'weights', 1.0} ); % E[ G(t+1) ] = 1.0*G(t) +- 0.1
    % I(t+1) := Normal dist. E = (1-alpha) * I(t) + alpha * beta * (G(t)-h)
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'DG.Meal', 1, ...
        {'mean',0.0,'cov', 10e-10, 'clamp_cov', 10e-10,'weights', 1.0} ); % E[ G(t+1) ] = 1.0*G(t) +- 0.1
    
    weights_G_minus_h1_map_T0= containers.Map(); % parents in slice t
    weights_G_minus_h1_map_T1= containers.Map(); % parents in slice t+1
    weights_G_minus_h1_map_T0('G_minus_Gb.Meal')= 0.0;
    weights_G_minus_h1_map_T1('G.Meal')= 1.0;
    weights_G_minus_h1_map_T1('Gb.Meal')= -1.0;
    % When using clamp, the root node is clamped to the N(0,I) distribution, so that we will not update these parameters during learning. 
    CPDFactories{end+1}=  ...
        CPDFactory('Gaussian_CPD', 'G_minus_Gb.Meal', 1, ...
        {'mean', 0.0, 'cov', 0.001}, ...
        weights_G_minus_h1_map_T0, weights_G_minus_h1_map_T1); % G_minus_h ~ Norm(E(G)-E(h))
    
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'Sb.Meal', 1, ...
        {'mean',0.0,'cov', 0.00001, 'weights', 1.0} ); % E[ G(t+1) ] = 1.0*G(t) +- 0.1
    
    weights_I1_map_T0= containers.Map(); % parents in slice t
    weights_I1_map_T1= containers.Map(); % parents in slice t+1
    INITIAL_ALPHA= alpha_Meal;
    INITIAL_BETA= beta_Meal;
    weights_I1_map_T0('I.Meal')= 1.0 - dt_Meal * INITIAL_ALPHA;% assume dt = 2 min
    weights_I1_map_T0('G_minus_Gb.Meal')= dt_Meal* INITIAL_ALPHA * INITIAL_BETA;
    CPDFactories{end+1} = ...
        CPDFactory('Gaussian_CPD', 'I.Meal', 1, ...
        {'mean',0.0,'cov', 0.001}, ...
        weights_I1_map_T0, weights_I1_map_T1);
    
    weights_S1_map_T0= containers.Map(); % parents in slice t
    weights_S1_map_T1= containers.Map(); % parents in slice t+1
    weights_S1_map_T1('DG.Meal')= INITIAL_K/dt_Meal;
    weights_S1_map_T1('Sb.Meal')= 1.0;
    weights_S1_map_T1('I.Meal')= 1.0;
    weights_S1_map_T0('S.Meal')= 0.0;
    % When using clamp, the root node is clamped to the N(0,I) distribution, so that we will not update these parameters during learning. 
    CPDFactories{end+1}=  ...
        CPDFactory('Gaussian_CPD', 'S.Meal', 1, ...
        {'mean', 0.0, 'cov', 0.001}, ...
        weights_S1_map_T0, weights_S1_map_T1); % G_minus_h ~ Norm(E(G)-E(h))
    
    % Final DBN factory
    dbn_factory= DBNFactory( ...
        node_names, edges_intra, edges_inter, ...
        eclass1_map, eclass2_map, CPDFactories);
  end

